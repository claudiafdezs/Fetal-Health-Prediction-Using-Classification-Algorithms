{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.15.1)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Using cached scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed imbalanced-learn-0.8.1 scikit-learn-1.0.1 threadpoolctl-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Using cached prettytable-2.4.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable) (0.1.9)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from prettytable) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->prettytable) (3.1.0)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt       \n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, classification_report,roc_auc_score,plot_confusion_matrix,cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "from statistics import mean, stdev\n",
    "#from sklearn import linear_model\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from prettytable import PrettyTable \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB     AC    FM     UC  ASTV  MSTV  ALTV  MLTV     DL   DS  ...  \\\n",
       "0     120.0    0.0   0.0    0.0  73.0   0.5  43.0   2.4    0.0  0.0  ...   \n",
       "1     132.0  240.0   0.0  240.0  17.0   2.1   0.0  10.4  120.0  0.0  ...   \n",
       "2     133.0  120.0   0.0  300.0  16.0   2.1   0.0  13.4  120.0  0.0  ...   \n",
       "3     134.0  120.0   0.0  360.0  16.0   2.4   0.0  23.0  120.0  0.0  ...   \n",
       "4     132.0  240.0   0.0  300.0  16.0   2.4   0.0  19.9    0.0  0.0  ...   \n",
       "...     ...    ...   ...    ...   ...   ...   ...   ...    ...  ...  ...   \n",
       "2121  140.0    0.0   0.0  360.0  79.0   0.2  25.0   7.2    0.0  0.0  ...   \n",
       "2122  140.0   60.0   0.0  540.0  78.0   0.4  22.0   7.1    0.0  0.0  ...   \n",
       "2123  140.0   60.0   0.0  420.0  79.0   0.4  20.0   6.1    0.0  0.0  ...   \n",
       "2124  140.0   60.0   0.0  540.0  78.0   0.4  27.0   7.0    0.0  0.0  ...   \n",
       "2125  142.0   60.0  60.0  300.0  74.0   0.4  36.0   5.0    0.0  0.0  ...   \n",
       "\n",
       "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \\\n",
       "0      62.0  126.0   2.0     0.0  120.0  137.0   121.0      73.0       1.0   \n",
       "1      68.0  198.0   6.0     1.0  141.0  136.0   140.0      12.0       0.0   \n",
       "2      68.0  198.0   5.0     1.0  141.0  135.0   138.0      13.0       0.0   \n",
       "3      53.0  170.0  11.0     0.0  137.0  134.0   137.0      13.0       1.0   \n",
       "4      53.0  170.0   9.0     0.0  137.0  136.0   138.0      11.0       1.0   \n",
       "...     ...    ...   ...     ...    ...    ...     ...       ...       ...   \n",
       "2121  137.0  177.0   4.0     0.0  153.0  150.0   152.0       2.0       0.0   \n",
       "2122  103.0  169.0   6.0     0.0  152.0  148.0   151.0       3.0       1.0   \n",
       "2123  103.0  170.0   5.0     0.0  153.0  148.0   152.0       4.0       1.0   \n",
       "2124  103.0  169.0   6.0     0.0  152.0  147.0   151.0       4.0       1.0   \n",
       "2125  117.0  159.0   2.0     1.0  145.0  143.0   145.0       1.0       0.0   \n",
       "\n",
       "      NSP  \n",
       "0     2.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  \n",
       "...   ...  \n",
       "2121  2.0  \n",
       "2122  2.0  \n",
       "2123  2.0  \n",
       "2124  2.0  \n",
       "2125  1.0  \n",
       "\n",
       "[2126 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import clean dataset\n",
    "df = pd.read_csv('/home/jovyan/CTG_clean.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['NSP'],axis=1).values     # features\n",
    "y = df['NSP'].values                   # classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Frequency in Original Dataset Histogram')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class frequency in imbalanced train set\n",
    "plt.hist(y, bins=3, rwidth=0.8)\n",
    "plt.xlabel('Class',fontsize=12)\n",
    "plt.ylabel('Count',fontsize=12)\n",
    "plt.title('Class Frequency in Original Dataset Histogram',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost classifier requires the classes to take integer values starting from 0.\n",
    "# Chang data type of the values in array y from float to integers. \n",
    "y = y.astype(int)\n",
    "print(y.dtype)              # check data type of y\n",
    "y_classes = list(set(y))    # check classes labels in y\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LabelEncoder to transform classes to 0,1,2.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)       # encode labels in y \n",
    "y_classes = list(set(y))                 # check the new classes labels\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the algorithms will be applied using K-Fold Cross Validation and Smote-NC to balance the train dataset in each iteration.\n",
    "Smote-NC will be applied as it provides better results for datasets that contains categorial variables. \n",
    "In the CTG dataset, the 'Tendency' feature (index = 20 in the dataset) is categorical, which has three possible values (0, 1 and 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold object with K=10 and Suffle to shuffle data before splitting.\n",
    "kf = KFold(n_splits=10, shuffle = True, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of accuracy score for each fold: [0.9483568075117371, 0.9530516431924883, 0.9530516431924883, 0.9483568075117371, 0.9436619718309859, 0.9483568075117371, 0.9386792452830188, 0.9339622641509434, 0.9386792452830188, 0.9575471698113207]\n",
      "\n",
      "Maximum Accuracy: 95.75 %\n",
      "Minimum Accuracy: 93.4 %\n",
      "\n",
      "Average Accuracy: 0.946\n",
      "Average Precision: 0.946\n",
      "Average Recall: 0.946\n",
      "Average F-1 Score: 0.945\n",
      "Average ROC-AUC: 0.988\n",
      "Avergae Cohen Kappa 0.896\n",
      "Avergae Matthew's Correlation Coef. 0.852\n",
      "Standard Deviation: 0.0075\n",
      "Average processing time: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Create classifier object\n",
    "forest = RandomForestClassifier(random_state=11)\n",
    "\n",
    "# Create list to store performance metrics\n",
    "accuracy_forest = []\n",
    "precision_forest = []\n",
    "recall_forest = []\n",
    "f1_forest = []\n",
    "rocauc_forest = []\n",
    "kappa_forest = []\n",
    "matthews_forest = []\n",
    "time_forest = []\n",
    "\n",
    "\n",
    "# Apply K-Fold Cross Validation \n",
    "# for each iteration:\n",
    "n=0\n",
    "for train_index, test_index in kf.split(x, y): \n",
    "    # start measuring processing time\n",
    "    start_fold = time.time() \n",
    "    \n",
    "    # split dataset into training and test sets.\n",
    "    x_train_fold, x_test_fold = x[train_index], x[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    # create augmentation object, where attribute with index 20 is categorical.\n",
    "    smote_nc = SMOTENC(categorical_features=[20])     \n",
    "    # apply SmoteNC to x_train and y_train\n",
    "    x_train_sm, y_train_sm = smote_nc.fit_resample(x_train_fold, y_train_fold)\n",
    "  \n",
    "    # fit the model to x_train_sm and y_train_sm\n",
    "    forest.fit(x_train_fold, y_train_fold)\n",
    "    # predict classes for x_test_fold\n",
    "    y_pred_fold = forest.predict(x_test_fold)\n",
    "    \n",
    "    # calculate performance metrics\n",
    "    accuracy =       accuracy_score(y_test_fold,y_pred_fold)\n",
    "    precision =      precision_score(y_test_fold,y_pred_fold, average='weighted',zero_division=0)   \n",
    "    recall =         recall_score(y_test_fold,y_pred_fold, average='weighted', zero_division=0)\n",
    "    f1 =             f1_score(y_test_fold,y_pred_fold, average='weighted')\n",
    "    rocauc =         roc_auc_score(y_test_fold,forest.predict_proba(x_test_fold), average='weighted', multi_class='ovo', max_fpr=None)\n",
    "    kappa =          cohen_kappa_score(y_test_fold,y_pred_fold,weights='quadratic')\n",
    "    matthews =       matthews_corrcoef(y_test_fold,y_pred_fold)\n",
    "    \n",
    "    # add metric scores to corresponding list\n",
    "    accuracy_forest.append(accuracy)\n",
    "    precision_forest.append(precision)\n",
    "    recall_forest.append(recall)\n",
    "    f1_forest.append(f1)\n",
    "    rocauc_forest.append(rocauc)\n",
    "    kappa_forest.append(kappa)\n",
    "    matthews_forest.append(matthews)\n",
    "    \n",
    "    # finish measuring processing time\n",
    "    end_fold = time.time() \n",
    "    # calculate total processing time\n",
    "    time_fold = end_fold - start_fold\n",
    "    # add processing time to time list\n",
    "    time_forest.append(time_fold)   \n",
    "\n",
    "    n+=1\n",
    "    \n",
    "\n",
    "# Calculate average of performance metrics of 10 folds.\n",
    "average_accuracy_forest = round(np.mean(accuracy_forest),3)\n",
    "average_precision_forest = round(np.mean(precision_forest),3)\n",
    "average_recall_forest =round(np.mean(recall_forest),3)\n",
    "average_f1_forest = round(np.mean(f1_forest),3)\n",
    "average_rocauc_forest = round(np.mean(rocauc_forest),3)\n",
    "average_kappa_forest =round(np.mean(kappa_forest),3)\n",
    "average_matthews_forest =round(np.mean(matthews_forest),3)\n",
    "stdv_forest = np.round(stdev(accuracy_forest),4)\n",
    "average_time_forest = round(np.mean(time_forest),1)\n",
    "\n",
    "\n",
    "# Print metrics.\n",
    "print('List of accuracy score for each fold:', accuracy_forest)\n",
    "print('\\nMaximum Accuracy:', np.round(max(accuracy_forest)*100,2),'%')\n",
    "print('Minimum Accuracy:', np.round(min(accuracy_forest)*100,2),'%')\n",
    "\n",
    "print('\\nAverage Accuracy:', average_accuracy_forest)\n",
    "print('Average Precision:', average_precision_forest)\n",
    "print('Average Recall:', average_recall_forest)\n",
    "print('Average F-1 Score:', average_f1_forest)\n",
    "print('Average ROC-AUC:', average_rocauc_forest)\n",
    "print('Avergae Cohen Kappa', average_kappa_forest)\n",
    "print(\"Avergae Matthew's Correlation Coef.\", average_matthews_forest)\n",
    "print('Standard Deviation:', stdv_forest)\n",
    "print('Average processing time:', average_time_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of accuracy score for each fold: [0.9107981220657277, 0.8732394366197183, 0.8779342723004695, 0.9436619718309859, 0.8779342723004695, 0.9248826291079812, 0.8820754716981132, 0.9198113207547169, 0.9245283018867925, 0.9481132075471698]\n",
      "\n",
      "Maximum Accuracy: 94.81 %\n",
      "Minimum Accuracy: 87.32 %\n",
      "\n",
      "Average Accuracy: 0.908\n",
      "Average Precision: 0.924\n",
      "Average Recall: 0.908\n",
      "Average F-1 Score: 0.913\n",
      "Average ROC-AUC: 0.971\n",
      "Avergae Cohen Kappa 0.83\n",
      "Avergae Matthew's Correlation Coef. 0.779\n",
      "Standard Deviation: 0.0284\n",
      "Average processing time: 2.3\n"
     ]
    }
   ],
   "source": [
    "# Create classifier object.\n",
    "xgb = XGBClassifier(learning_rate=0.001,use_label_encoder=False, objective = \"multi:softprob\", eval_metric='mlogloss') \n",
    "\n",
    "# Create list to store performance metrics\n",
    "accuracy_xgb = []\n",
    "accuracy_xgb = []\n",
    "precision_xgb = []\n",
    "recall_xgb = []\n",
    "f1_xgb = []\n",
    "rocauc_xgb = []\n",
    "kappa_xgb = []\n",
    "matthews_xgb = []\n",
    "time_xgb = []\n",
    "\n",
    "\n",
    "# Apply K-Fold Cross Validation \n",
    "# for each iteration:\n",
    "n=0\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    # start measuring processing time\n",
    "    start_fold = time.time() \n",
    "    \n",
    "    # split dataset into training and test sets.\n",
    "    x_train_fold, x_test_fold = x[train_index], x[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    # create augmentation object, where attribute with index 20 is categorical.\n",
    "    smote_nc = SMOTENC(categorical_features=[20])\n",
    "    # apply SmoteNC to x_train and y_train\n",
    "    x_train_sm, y_train_sm = smote_nc.fit_resample(x_train_fold, y_train_fold)\n",
    "  \n",
    "    # fit the model to x_train_sm and y_train_sm\n",
    "    xgb.fit(x_train_sm, y_train_sm)\n",
    "    # predict classes for x_test_fold\n",
    "    y_pred_fold = xgb.predict(x_test_fold)\n",
    "    \n",
    "    # calculate performance metrics\n",
    "    accuracy =       accuracy_score(y_test_fold,y_pred_fold)\n",
    "    precision =      precision_score(y_test_fold,y_pred_fold, average='weighted',zero_division=0)\n",
    "    recall =         recall_score(y_test_fold,y_pred_fold, average='weighted', zero_division=0)\n",
    "    f1 =             f1_score(y_test_fold,y_pred_fold, average='weighted')\n",
    "    rocauc =         roc_auc_score(y_test_fold,xgb.predict_proba(x_test_fold), average='weighted', multi_class='ovo', max_fpr=None)\n",
    "    kappa =          cohen_kappa_score(y_test_fold,y_pred_fold,weights='quadratic')\n",
    "    matthews =       matthews_corrcoef(y_test_fold,y_pred_fold)\n",
    "    \n",
    "    # add metric scores to corresponding list\n",
    "    accuracy_xgb.append(accuracy)\n",
    "    precision_xgb.append(precision)\n",
    "    recall_xgb.append(recall)\n",
    "    f1_xgb.append(f1)\n",
    "    rocauc_xgb.append(rocauc)\n",
    "    kappa_xgb.append(kappa)\n",
    "    matthews_xgb.append(matthews)\n",
    "    \n",
    "    # finish measuring processing time\n",
    "    end_fold = time.time() \n",
    "    # calculate total processing time\n",
    "    time_fold = end_fold - start_fold\n",
    "    # add processing time to time list\n",
    "    time_xgb.append(time_fold)  \n",
    "\n",
    "    n+=1\n",
    "\n",
    "\n",
    "# Calculate average of performance metrics of 10 folds.\n",
    "average_accuracy_xgb = round(np.mean(accuracy_xgb),3)\n",
    "average_precision_xgb = round(np.mean(precision_xgb),3)\n",
    "average_recall_xgb =round(np.mean(recall_xgb),3)\n",
    "average_f1_xgb = round(np.mean(f1_xgb),3)\n",
    "average_rocauc_xgb = round(np.mean(rocauc_xgb),3)\n",
    "average_kappa_xgb =round(np.mean(kappa_xgb),3)\n",
    "average_matthews_xgb =round(np.mean(matthews_xgb),3)\n",
    "stdv_xgb = np.round(stdev(accuracy_xgb),4)\n",
    "average_time_xgb = round(np.mean(time_xgb),1)\n",
    "\n",
    "\n",
    "# Print metrics.\n",
    "print('List of accuracy score for each fold:', accuracy_xgb)\n",
    "print('\\nMaximum Accuracy:', np.round(max(accuracy_xgb)*100,2),'%')\n",
    "print('Minimum Accuracy:', np.round(min(accuracy_xgb)*100,2),'%')\n",
    "\n",
    "print('\\nAverage Accuracy:', average_accuracy_xgb)\n",
    "print('Average Precision:', average_precision_xgb)\n",
    "print('Average Recall:', average_recall_xgb)\n",
    "print('Average F-1 Score:', average_f1_xgb)\n",
    "print('Average ROC-AUC:', average_rocauc_xgb)\n",
    "print('Avergae Cohen Kappa', average_kappa_xgb)\n",
    "print(\"Avergae Matthew's Correlation Coef.\", average_matthews_xgb)\n",
    "print('Standard Deviation:', stdv_xgb)\n",
    "print('Average processing time:', average_time_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP (Scaling &  K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifier requires the dataset to be scaled. \n",
    "scaler = preprocessing.StandardScaler()      # Create Scaling object\n",
    "x_scaled = scaler.fit_transform(x)           # Scale x (features) to apply MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of accuracy score for each fold: [0.9436619718309859, 0.9389671361502347, 0.9295774647887324, 0.9389671361502347, 0.9577464788732394, 0.9483568075117371, 0.9198113207547169, 0.9150943396226415, 0.9386792452830188, 0.9433962264150944]\n",
      "\n",
      "Maximum Accuracy: 95.77 %\n",
      "Minimum Accuracy: 91.51 %\n",
      "\n",
      "Average Accuracy: 0.937\n",
      "Average Precision: 0.94\n",
      "Average Recall: 0.937\n",
      "Average F-1 Score: 0.938\n",
      "Average ROC-AUC: 0.98\n",
      "Avergae Cohen Kappa 0.885\n",
      "Avergae Matthew's Correlation Coef. 0.833\n",
      "Standard Deviation: 0.0128\n",
      "Average processing time: 18.0\n"
     ]
    }
   ],
   "source": [
    "# Create classifier object.\n",
    "mlp = MLPClassifier(max_iter = 800)\n",
    "\n",
    "# Create list to store performance metrics\n",
    "accuracy_mlp = []\n",
    "precision_mlp = []\n",
    "recall_mlp = []\n",
    "f1_mlp = []\n",
    "rocauc_mlp = []\n",
    "kappa_mlp = []\n",
    "matthews_mlp = []\n",
    "time_mlp = []\n",
    "\n",
    "# Apply K-Fold Cross Validation \n",
    "# for each iteration:\n",
    "n=0\n",
    "for train_index, test_index in kf.split(x_scaled, y):\n",
    "    # start measuring processing time\n",
    "    start_fold = time.time() \n",
    "\n",
    "    # split dataset into training and test sets. X in this case is x_scaled.\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    # create augmentation object, where attribute with index 20 is categorical.\n",
    "    smote_nc = SMOTENC(categorical_features=[20])\n",
    "    # apply SmoteNC to x_train and y_train\n",
    "    x_train_sm, y_train_sm = smote_nc.fit_resample(x_train_fold, y_train_fold)\n",
    "  \n",
    "    # fit the model to x_train_sm and y_train_sm\n",
    "    mlp.fit(x_train_sm, y_train_sm)\n",
    "    # predict classes for x_test_fold\n",
    "    y_pred_fold = mlp.predict(x_test_fold)\n",
    "    \n",
    "    # calculate performance metrics\n",
    "    accuracy =       accuracy_score(y_test_fold,y_pred_fold)\n",
    "    precision =      precision_score(y_test_fold,y_pred_fold, average='weighted',zero_division=0)\n",
    "    recall =         recall_score(y_test_fold,y_pred_fold, average='weighted', zero_division=0)\n",
    "    f1 =             f1_score(y_test_fold,y_pred_fold, average='weighted')\n",
    "    rocauc =         roc_auc_score(y_test_fold,mlp.predict_proba(x_test_fold), average='weighted', multi_class='ovo', max_fpr=None)\n",
    "    kappa =          cohen_kappa_score(y_test_fold,y_pred_fold,weights='quadratic')\n",
    "    matthews =       matthews_corrcoef(y_test_fold,y_pred_fold)\n",
    "    \n",
    "    # add metric scores to corresponding list\n",
    "    accuracy_mlp.append(accuracy)\n",
    "    precision_mlp.append(precision)\n",
    "    recall_mlp.append(recall)\n",
    "    f1_mlp.append(f1)\n",
    "    rocauc_mlp.append(rocauc)\n",
    "    kappa_mlp.append(kappa)\n",
    "    matthews_mlp.append(matthews)\n",
    "\n",
    "    # finish measuring processing time\n",
    "    end_fold = time.time() \n",
    "    # calculate total processing time\n",
    "    time_fold = end_fold - start_fold\n",
    "    # add processing time to time list\n",
    "    time_mlp.append(time_fold)\n",
    "    \n",
    "    n+=1\n",
    "\n",
    "\n",
    "# Calculate average of performance metrics of 10 folds.\n",
    "average_accuracy_mlp = round(np.mean(accuracy_mlp),3)\n",
    "average_precision_mlp = round(np.mean(precision_mlp),3)\n",
    "average_recall_mlp =round(np.mean(recall_mlp),3)\n",
    "average_f1_mlp = round(np.mean(f1_mlp),3)\n",
    "average_rocauc_mlp = round(np.mean(rocauc_mlp),3)\n",
    "average_kappa_mlp =round(np.mean(kappa_mlp),3)\n",
    "average_matthews_mlp =round(np.mean(matthews_mlp),3)\n",
    "stdv_mlp = np.round(stdev(accuracy_mlp),4)\n",
    "average_time_mlp = round(np.mean(time_mlp),1)\n",
    "    \n",
    "# Print metrics.\n",
    "print('List of accuracy score for each fold:', accuracy_mlp)\n",
    "print('\\nMaximum Accuracy:', np.round(max(accuracy_mlp)*100,2),'%')\n",
    "print('Minimum Accuracy:', np.round(min(accuracy_mlp)*100,2),'%')\n",
    "\n",
    "print('\\nAverage Accuracy:', average_accuracy_mlp)\n",
    "print('Average Precision:', average_precision_mlp)\n",
    "print('Average Recall:', average_recall_mlp)\n",
    "print('Average F-1 Score:', average_f1_mlp)\n",
    "print('Average ROC-AUC:', average_rocauc_mlp)\n",
    "print('Avergae Cohen Kappa', average_kappa_mlp)\n",
    "print(\"Avergae Matthew's Correlation Coef.\", average_matthews_mlp)\n",
    "print('Standard Deviation:', stdv_mlp)\n",
    "print('Average processing time:', average_time_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Algorithms Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Metrics of Models Generated with K-Fold Cross Validation\n",
      "+-----------------------+---------------+---------+--------+\n",
      "|         Metric        | Random Forest | XGBoost |  MLP   |\n",
      "+-----------------------+---------------+---------+--------+\n",
      "|        Accuracy       |     0.946     |  0.908  | 0.937  |\n",
      "|       Precision       |     0.946     |  0.924  |  0.94  |\n",
      "|         Recall        |     0.946     |  0.908  | 0.937  |\n",
      "|       F-1 Score       |     0.945     |  0.913  | 0.938  |\n",
      "|        ROC-AUC        |     0.988     |  0.971  |  0.98  |\n",
      "|     Cohen's Kappa     |     0.896     |   0.83  | 0.885  |\n",
      "| Matthew's Corr. Coef. |     0.852     |  0.779  | 0.833  |\n",
      "|     Accuracy St.Dv    |     0.0075    |  0.0284 | 0.0128 |\n",
      "|      Average Time     |      0.5      |   2.3   |  18.0  |\n",
      "+-----------------------+---------------+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Define table's column's names.\n",
    "Performance_Metrics = PrettyTable([\"Metric\", \"Random Forest\", \"XGBoost\", \"MLP\"]) \n",
    "  \n",
    "# Add rows to the table\n",
    "Performance_Metrics.add_row([\"Accuracy\",     average_accuracy_forest,         average_accuracy_xgb,  average_accuracy_mlp]) \n",
    "Performance_Metrics.add_row([\"Precision\",    average_precision_forest,        average_precision_xgb, average_precision_mlp]) \n",
    "Performance_Metrics.add_row([\"Recall\",       average_recall_forest,           average_recall_xgb,    average_recall_mlp]) \n",
    "Performance_Metrics.add_row([\"F-1 Score\",    average_f1_forest,               average_f1_xgb,        average_f1_mlp])\n",
    "Performance_Metrics.add_row([\"ROC-AUC\",      average_rocauc_forest,           average_rocauc_xgb,    average_rocauc_mlp])\n",
    "Performance_Metrics.add_row([\"Cohen's Kappa\", average_kappa_forest,           average_kappa_xgb,     average_kappa_mlp])\n",
    "Performance_Metrics.add_row([\"Matthew's Corr. Coef.\", average_matthews_forest,average_matthews_xgb,  average_matthews_mlp])\n",
    "Performance_Metrics.add_row([\"Accuracy St.Dv\",stdv_forest,                    stdv_xgb,              stdv_mlp]) \n",
    "Performance_Metrics.add_row([\"Average Time\",average_time_forest,             average_time_xgb,      average_time_mlp]) \n",
    "\n",
    "\n",
    "print('Average Performance Metrics of Models Generated with K-Fold Cross Validation')\n",
    "print(Performance_Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
